# -*- coding: utf-8 -*-
"""02Assignment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hCan7p4SXTYcSjiM1BQI9HFoZNYCWKkL

1. Load a clasification dataset and create 75/25 train/test split.
"""

from sklearn.datasets import load_wine
wine = load_wine ()
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(wine.data, wine.target,test_size = 0.25, random_state=42)

"""2. Stratified 5 fold cross validation on the training dataset, use precision to assess (a).KNN: find optimal hyperparameters for the distance metric (i.e., test \Euclidean" and \Manhattan") find number of nearest neighbors(i.e., test at least 5 different values) when using k-Nearest Neighbors.Report the
optimal hyperparameters found and how many hyperparameter combinations you
tested in total.


> The code is as below. Based on the results, the optimal distance metric is manhattan distance (p=1), and the optimal number of nearest neighbors being 8 (n_neighbors = 8) with the optimal precision score on training being 0.74. In my case, the total hyperparmeter combinations I tested was 8*2=16.
"""

# Commented out IPython magic to ensure Python compatibility.
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import StratifiedKFold

import matplotlib.pyplot as plt
# %matplotlib inline

# p = 1, this is equivalent to using manhattan_distance (l1)
# p=2, this is euclidean_distance (l2) 

def plotNumNeighborsVsAccuracy():
  
  p_setting = range (1,3)
  best_score = 0

  for p_value in p_setting:

    fold_train_precision = []
    best_score_n=0
    neighbor_settings = range (3,11)

    for curKvalue in neighbor_settings:
      clf =  KNeighborsClassifier(n_neighbors = curKvalue, p = p_value)
      clf.fit(x_train, y_train)
      kfold_shuffled = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)
      train_precision = cross_val_score(clf, x_train, y_train, cv=kfold_shuffled,scoring='precision_micro')
      avg_train_precision = train_precision.mean()
      fold_train_precision.append(avg_train_precision)
      if avg_train_precision > best_score_n:
        best_param_n = {'n_neighbors': curKvalue}
        best_score_n = avg_train_precision
    print("best score on training:{:0.2f}".format(best_score_n))
    print('best parameters:{}'.format(best_param_n))
    plt.plot(neighbor_settings,fold_train_precision,label ='trianing precision')
    plt.ylabel('precision')
    plt.xlabel('number of neighbors')
    plt.legend()
    plt.show()

    if best_score_n > best_score:
      best_score = best_score_n
      best_param = {'p': p_value}
   
  print("best score on training:{:0.2f}".format(best_score))
  print('best parameters:{}'.format(best_param))

plotNumNeighborsVsAccuracy()

"""2. (b) Decision tree: find the optimal hyperparameters for the split criterion (i.e., test\gini" and \entropy") and tree depth (i.e., test at least 5 different values) when training a decision tree. Report the optimal hyperparameters found and how many hyperparameter combinations you tested in total. (Code and Write-up)



> The code is as below. The optimal hyperparameters are entropy (criterion = 'entropy') and 9 for tree depth (max_depth =  9), with the best precision score of 0.92. In my case, I tested 10*2=20 hyperparameter combinations.
"""

from sklearn.tree import DecisionTreeClassifier
best_score = 0
gini_precision = []
setting = range (1,11)
for dvalue in setting:
  tree_giniIndex = DecisionTreeClassifier (criterion='gini', max_depth = dvalue)
  tree_giniIndex.fit(x_train, y_train)
  kfold_shuffled = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)
  train_precision_gini = cross_val_score(tree_giniIndex,x_train,y_train, cv=kfold_shuffled, scoring= 'precision_micro')
  avg_train_precision_gini = train_precision_gini.mean()
  gini_precision.append(avg_train_precision_gini)
  if avg_train_precision_gini > best_score:
    best_param = {'max_depth': dvalue}
    best_score = avg_train_precision_gini
print("best score on training:{:0.2f}".format(best_score))
print('best parameters:{}'.format(best_param))
plt.plot(setting, gini_precision, label = 'gini trianing precision')
plt.ylabel('precision')
plt.xlabel('max depth')
plt.legend()
plt.show()


best_score = 0
entropy_precision = []
for dvalue in setting:
  tree_entropyIndex=DecisionTreeClassifier(criterion='entropy',max_depth=dvalue)
  tree_entropyIndex.fit(x_train, y_train)
  kfold_shuffled = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)
  train_precision_entropy = cross_val_score(tree_entropyIndex, x_train, y_train, cv=kfold_shuffled, scoring= 'precision_micro')
  avg_train_precision_entropy = train_precision_entropy.mean()
  entropy_precision.append(avg_train_precision_entropy)
  if avg_train_precision_entropy > best_score:
    best_param = {'max_depth': dvalue}
    best_score = avg_train_precision_entropy
print("best score on training:{:0.2f}".format(best_score))
print('best parameters:{}'.format(best_param))
plt.plot(setting, entropy_precision, 'g', label = 'entropy trianing precision')
plt.ylabel('precision')
plt.xlabel('max depth')
plt.legend()
plt.show()

"""2. (c) Support Vector Machine (SVM): find the optimal hyperparameters for the poly-nomial degree, kernel bandwidth (i.e., gamma), and regularization parameter (i.e.,C) when training a kernel SVM with a polynomial kernel. You must evaluate all possible combinations of at least 3 degree values (for the polynomial degree), at least 3 gamma values, and at least 3 C values. Report the optimal hyperparameters found and how many hyperparameter combinations you tested in total.

The optimal hyperparameters are:

poly-nomial degree: 1 

kernel bandwidth/gamma: 0.1

regularization parameter/C : 1.7

best precision performance: 0.94

I tested in total 27 hyperparameter combinations.
"""

svmsetting = range (1,4)
svc_precision = []

from sklearn.svm import SVC
c_value = 0.1
best_score = 0

for epoch1 in svmsetting:
  gamma_value = 0.1

  for epoch2 in svmsetting:
    degree_value = 1

    for epoch3 in svmsetting:
      poly_kernel_svm_clf = SVC(C= c_value,kernel='poly',degree = degree_value, 
                                gamma= gamma_value) 
      poly_kernel_svm_clf.fit (x_train,y_train)

      kfold_shuffled = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)
      train_precision = cross_val_score(poly_kernel_svm_clf, x_train, y_train, 
                                  cv=kfold_shuffled, scoring= 'precision_micro')
      avg_train_precision = train_precision.mean()
      svc_precision.append(avg_train_precision)
      param={'degree': degree_value,'C': c_value, 'gamma': gamma_value, 
             'precision':avg_train_precision}
      print (param)

      if avg_train_precision > best_score:
        best_param = {'degree': degree_value,'C': c_value, 'gamma': gamma_value}
        best_score = avg_train_precision

      degree_value = degree_value + 1
    gamma_value = gamma_value + 0.5
  c_value = c_value + 0.8

print("best score on training:{:0.2f}".format(best_score))
print('best parameters:{}'.format(best_param))

"""3. (a) Retrain each of the three models (i.e., Decision tree, K-NN, and SVM) on all the training data using the optimal hyperparameters found in part 2. Also train a Gaussian Naive Bayes model on all the training data."""

from sklearn.naive_bayes import GaussianNB

clf_gaussian = GaussianNB ()
clf_gaussian.fit(x_train, y_train)

clf_KNN =  KNeighborsClassifier(n_neighbors = 7, p = 1)
clf_KNN.fit(x_train, y_train)

clf_svm = SVC(C= 0.1, kernel='poly', degree = 1, gamma= 0.6) 
clf_svm.fit (x_train,y_train)

tree_entropyIndex = DecisionTreeClassifier (criterion='gini', max_depth = 7)
tree_entropyIndex.fit(x_train, y_train)

"""3. (b) Report the predictive performance on the test dataset for each of the four models from part (a) with respect to each of the following evaluation metrics: accuracy, precision, and recall. (Code and Write-up)

For Gaussian, the accuracy score is 1.00, the precision score (weighted average) is 1.00 and the recall score (weighted average) is 1.00.

For KNN, the accuracy score is 0.76, the precision score (weighted average) is 0.76, and the recall score (weighted average) is 0.76.

For SVM, the accuracy score is 1.00, the precision score (weighted average) is 1.00 and the recall score (weighted average) is 1.00.

For Decision Tree, the accuracy score is 0.89, the precision score (weighted average) is 0.91 and the recall score (weighted average) is 0.89.
"""

y_predictedNB = clf_gaussian.predict(x_test)
y_predictedKNN = clf_KNN.predict(x_test)
y_predictedSVM = clf_svm.predict(x_test)
y_predictedTree = tree_entropyIndex.predict(x_test)

from sklearn.metrics import classification_report
print ("report for Gaussian:\n", classification_report (y_predictedNB, y_test))

from sklearn.metrics import classification_report
print ("report for KNN:\n", classification_report (y_predictedKNN, y_test))

from sklearn.metrics import classification_report
print ("report for SVM:\n", classification_report (y_predictedSVM, y_test))

from sklearn.metrics import classification_report
print ("report for Decision Tree:\n", classification_report (y_predictedTree,y_test))

"""3. (c) Visualize the predictive performance of the each of the four models from part (a) by showing the resulting confusion matrix for each model."""

from sklearn.metrics import confusion_matrix
import seaborn as sns
mat=confusion_matrix(y_predictedNB, y_test)
sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)
plt.xlabel('True label')
plt.ylabel('Predicted label')

mat=confusion_matrix(y_predictedKNN, y_test)
sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)
plt.xlabel('True label')
plt.ylabel('Predicted label')

mat=confusion_matrix(y_predictedSVM, y_test)
sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)
plt.xlabel('True label')
plt.ylabel('Predicted label')

mat=confusion_matrix(y_predictedTree, y_test)
sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)
plt.xlabel('True label')
plt.ylabel('Predicted label')

"""3. (d) Write a discussion analyzing and comparing the performance of the four models.
For example, which method(s) perform the best and why do you think so? Which
method(s) perform the worst and why do you think so? What do the different performance metrics tell you about the results? Your discussion should consist of two to three paragraphs. (Write-up).

Based on the results and heat maps above, the Gaussian and SVM models have the best performance on test data, both scoring 1.0 for the accuracy, precision and recall score. Decision tree has an average precision score of 0.91, indicating better performance than KNN with the average precision score of 0.76. The accuracy and recall scores of Decision tree also outstand those of KNN. In this case, the Gaussian and SVM models have the best performance whilst the KNN has the worst performance.

Reason analysis:

1) Hyperparameters. The SVM model has better performance because in previous steps, I calculated 27 hyperparameter combinations and selected out three hyperparameters that contributed to the best performance. For KNN and decision tree, I made less calculation on hyperparameter combinations and only selected out 2 hyperparameters that contributed to the best performance. These two models could be improved by improved hyperparameters based on increased calculations.

2) Model suitability. While these models are being trained, SVM has a better training performance on the precision score than Decision tree or KNN. Reflecting upon the results, the reason might also be that SVM and Gaussian NB models play better roles in realizing classifications in this case. Another reason behind this might be that for the classification dataset of wine, models could be developed to predict the classification labels based on the features. Gaussian, SVM and decision tree are developed based on models whilst KNN is developed based on comparing instances. In this case, the first three models have better performance as their algorithms suited better the dataset.

4. (a) Evaluate each of the following classifiers using 5-fold cross validation: (Code) i. Majority vote classifier that uses the four classifiers from part 3 of this assignment ii. Bagging method iii. Boosting method
"""

from sklearn.ensemble import VotingClassifier

clf1 = clf_gaussian
clf2 = clf_KNN
clf3 = clf_svm
clf4 = tree_entropyIndex

votingClf=VotingClassifier(estimators=[('gnb', clf1),('knn', clf2),('svc',clf3),('tree', clf4)], voting='hard')
votingClf.fit(x_train, y_train)

kfold_shuffled = StratifiedKFold (n_splits=5, shuffle=True, random_state=2)
voting_precision = cross_val_score(votingClf,x_train,y_train,cv=kfold_shuffled, scoring= 'precision_micro')
avg_voting_precision = voting_precision.mean()
voting_recall = cross_val_score(votingClf, x_train, y_train, cv=kfold_shuffled, scoring= 'recall_micro')
avg_voting_recall = voting_recall.mean()
print ("precision score of majority vote classifier:", avg_voting_precision)
print ("recall score of majority vote classifier:", avg_voting_recall)

from sklearn.ensemble import BaggingClassifier

bagging = BaggingClassifier()
bagging.fit(x_train, y_train)

kfold_shuffled = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)
bagging_precision = cross_val_score(bagging, x_train, y_train, cv=kfold_shuffled, scoring= 'precision_micro')
avg_bagging_precision = bagging_precision.mean()
bagging_recall = cross_val_score(bagging, x_train, y_train, cv=kfold_shuffled, scoring= 'recall_micro')
avg_bagging_recall = bagging_recall.mean()
print ("precision score of bagging classifier:", avg_bagging_precision)
print ("recall score of bagging classifier:", avg_bagging_recall)

from sklearn.ensemble import AdaBoostClassifier

adabooster = AdaBoostClassifier(n_estimators = 50)
adabooster.fit(x_train, y_train)

kfold_shuffled = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)
adabooster_precision = cross_val_score(adabooster, x_train, y_train, 
                                cv=kfold_shuffled, scoring= 'precision_micro')
avg_adabooster_precision = adabooster_precision.mean()
adabooster_recall = cross_val_score(adabooster, x_train, y_train, 
                                    cv=kfold_shuffled, scoring= 'recall_micro')
avg_adabooster_recall = adabooster_recall.mean()
print ("precision score of adabooster classifier:", avg_adabooster_precision)
print ("recall score of adabooster classifier:", avg_adabooster_recall)

